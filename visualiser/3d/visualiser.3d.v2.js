console.log("This project uses TrackballControls.js which was authored by Eberhard Graether, Mark Lundin, Simone Manini and Luca Antiga. The Three.JS project is released under the MIT license which is available at their repo where: https://github.com/mrdoob/three.js/blob/dev/LICENSE.");
console.log("This project also uses ThreeJS which is released under the same license (as the TrackballControls are in the same project) so see the license above.")

////////////////////////////////////-\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\
//  _____ _                       _ ____    ____                       \\
// |_   _| |__  _ __ ___  ___    | / ___|  / ___|  ___ ___ _ __   ___  \\
//   | | | '_ \| '__/ _ \/ _ \_  | \___ \  \___ \ / __/ _ \ '_ \ / _ \ \\
//   | | | | | | | |  __/  __/ |_| |___) |  ___) | (_|  __/ | | |  __/ \\
//   |_| |_| |_|_|  \___|\___|\___/|____/  |____/ \___\___|_| |_|\___| \\
//\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\-////////////////////////////////////

// Register the stats element
// This tracks the FPS of the current animation
// This is pointless in production but useful in development but I'm leaving it in anyway
var stats = new Stats();
stats.showPanel(0);
document.body.appendChild($(stats.domElement).attr("id", "info")[0]);

/**
 * Stores all of the colors generated by the interpolateColors function and accessed via the getStop function.
 * @type {Array}
 */
let colorInterpolation = [];

/**
 * Converts a hex string to an rgb array
 * @param {string} hex A hex formatted color string, either starting with a hash or not. 
 * @return {Array} a three element array representing rgb values (in that order). If the input was invalid it will return null.
 */
function hexToRgb(hex) {
    var result = /^#?([a-f\d]{2})([a-f\d]{2})([a-f\d]{2})$/i.exec(hex);
    return result ? [
        parseInt(result[1], 16),
        parseInt(result[2], 16),
        parseInt(result[3], 16)
    ] : null;
}

// The following function was taken from https://graphicdesign.stackexchange.com/a/83867
// As a result, I don't actually know how it works. Took people smarter than I to do that
// I've made some modifications to this to make it work in the scenario but its basically the same

function interpolateColor(color1, color2, factor) {
    if (arguments.length < 3) {
        factor = 0.5;
    }
    var result = color1.slice();
    for (var i = 0; i < 3; i++) {
        result[i] = Math.round(result[i] + factor * (color2[i] - color1[i]));
    }
    return result;
}

function interpolateColorsReal(minColor, maxColor, colorStops) {
    let interpolations = [];
    let stepFactor = 1 / (colorStops - 1);
    for (let i = 0; i < colorStops; i++) {
        interpolations.push(interpolateColor(minColor, maxColor, stepFactor * i));
    }
    return interpolations;
}

function interpolateColors(stops, ...colors) {
    let stopsPerColor = Math.round(stops / (colors.length - 1));
    for (let i = 0; i < colors.length - 1; i++) {
        if (typeof(colors[i]) === "string") colors[i] = hexToRgb(colors[i]);
        if (typeof(colors[i + 1]) === "string") colors[i + 1] = hexToRgb(colors[i + 1]);
        colorInterpolation = colorInterpolation.concat(interpolateColorsReal(colors[i], colors[i + 1], stopsPerColor));
    }
    for (let i = colorInterpolation.length; i < stops; i++) {
        colorInterpolation.push([0, 0, 0]);
    }
}

/**
 * Returns a color at a particular distance within the interpolation range. If the requested stop is too large, the last element will be returned
 * @param {Number} level the interpolation stop to fetch
 * @return {Array} the color at this stop or at the last stop if the number if too large
 */
function getStop(level) {
    if (level >= colorInterpolation.length) return colorInterpolation[colorInterpolation.length];
    return colorInterpolation[level];
}

// Generate 255 stops as that is the greatest that the frequency data and time domain data below can be. 
// This should provide a unique colour for each value
interpolateColors(255, "#b21f1f", "#1a2a6c");

/**
 * Maps a given number 'x' which is within the range inMin <= x <= inMax to a given output in the range outMin <= map(x) <= outMax
 * Code was adapted from that of the Arduino core
 * @param {Number} x the number to map within the range
 * @param {Number} inMin the minimum possible value of x
 * @param {Number} inMax the maximum possible value of x
 * @param {Number} outMin the minimum value to output
 * @param {Number} outMax the maximum value to output
 * @return {Number} the mapped number within the range outMin <= map(x) <= outMax providing that x meets the condition inMin <= x <= inMax
 */
function map(x, inMin, inMax, outMin, outMax) {
    return (x - inMin) * (outMax - outMin) / (inMax - inMin) + outMin;
}

// Begin the actual 3D scene that we will be using to render the visualiser
// To render the environment we need four main components
//  1) a scene to contain all of the object
//  2) a camera within that scene to see the objects
//  3) a renderer connected to that camera which will create an output for the user
//  4) a set of controls so that the user can interact with the visualiser
// For this setup I am using the TrackballControls as it provides the best method of navigation from the example controls that I've seen.
// Due to the scales that this render is working on, I've bumped up the far range on the camera pretty significantly so that it will nearly always
//   keep the spheres in view.
var scene = new THREE.Scene();
var camera = new THREE.PerspectiveCamera(75, window.innerWidth / window.innerHeight, 0.1, 10000);
var renderer = new THREE.WebGLRenderer();
var controls = new THREE.TrackballControls(camera);

// We need to set an initial position for the camera or the trackball controls seem to throw a bit
//   of a fit. This value is just picked from testing
camera.position.z = 100;

// Initialise the renderer with the size of the window which will cause the canvas to scale to it. This is
//   just the initial size and it can be altered later on if the window is resized, see the onWindowResized event
//   below
// We also add the dom element to the body which is the canvas on which all the rendering will be done
renderer.setSize(window.innerWidth, window.innerHeight);
document.body.appendChild(renderer.domElement);

// This is the scale that the entire scene is acting on. It represents the maximum possible radius of a point on the ring
//   and is used in some other calculations to keep everything consistent
var scale = 128 * 8;

// There is no real need to group all the points together but it seemed like a good idea at the time
// If I go on to expand this it allows me to add universal modifiers to the points such as scaling all of
//   them at once
var pointGroup = new THREE.Group();
// This maps a point from 0-127 to one of the 128 spheres.
var pointMapping = [];

// We need to generate 1024 spheres as we will be setting the fftSize to 2048 and will have 1024 data points in
//   out data buffer, each of which corresponds to a sphere.
// Each sphere is positioned at the position (0, 0, 0) and has a basic material meaning that it is not effected
//   by light so we don't have to worry about adding lights or anything like that
for (let i = 0; i < 1024; i++) {
    var point = new THREE.SphereGeometry(4, 6, 6, 0, Math.PI * 2, 0, Math.PI * 2);
    var material = new THREE.MeshBasicMaterial();
    var sphere = new THREE.Mesh(point, material);
    sphere.position.x = 0;
    sphere.position.y = 0;
    sphere.position.z = 0;

    pointMapping.push(sphere);
    pointGroup.add(sphere);
}
// Once all the spheres are added, we need to add the group of them to the scene
scene.add(pointGroup);

/**
 * The animation of the 3D environment. 
 * On each run, a new frame will be requested, the controls updated and the scene rendered.
 * Stats metrics are also run to calculate the FPS and MS of runs
 */
function animate() {
    stats.begin();
    requestAnimationFrame(animate);

    controls.update();
    renderer.render(scene, camera);
    stats.end();
}

/**
 * Handles the resizing of the window.
 * It allows the camera and the canvas to compensate for the change in size. This is based on example code
 * in the three js examples so there may be an explanation there.
 */
function onWindowResize() {
    camera.aspect = window.innerWidth / window.innerHeight;
    camera.updateProjectionMatrix();
    renderer.setSize(window.innerWidth, window.innerHeight);
    controls.handleResize();
}
// Register the function for the resize event of the window
window.addEventListener('resize', onWindowResize, false);

// Launch the animation of the 3D renderer
animate();

////////////////////////////////////-\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\
//     _             _ _            _                _           _     \\
//    / \  _   _  __| (_) ___      / \   _ __   __ _| |_   _ ___(_)___  \\
//   / _ \| | | |/ _` | |/ _ \    / _ \ | '_ \ / _` | | | | / __| / __| \\
//  / ___ \ |_| | (_| | | (_) |  / ___ \| | | | (_| | | |_| \__ \ \__ \ \\
// /_/   \_\__,_|\__,_|_|\___/  /_/   \_\_| |_|\__,_|_|\__, |___/_|___/ \\
//                                                     |___/            \\
//\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\-/////////////////////////////////////

// Holds the instance of the sound object so it can be manipulated from elsewhere
let sound = null;

/**
 * Triggered when the user selects an audio file.
 * It constructs the Pizzicato sound object, sets up the audio analyzer and the manipulation function
 * It will play the sound and immediately stop it so that it creates the correct context which allows the sound
 *   to then be controlled from elsewhere
 * @param {object} data the data to be passed to the Pizzicato.Sound constructor directly
 */
function visualise(data) {
    var analyser = Pizzicato.context.createAnalyser();
    sound = new Pizzicato.Sound(data, function() {
        // Attach the analyser to the actual sound file that is playing
        sound.connect(analyser);
        // Define our size so we know how many points we will be getting
        analyser.fftSize = 2048;
        // This is how many points we are actually getting. It should be equal to fftSize/2 so 1024 which is the
        //   number of spheres we created earlier
        var bufferLength = analyser.frequencyBinCount;

        // Initialise two arrays to hold our data
        var frequencyData = new Uint8Array(bufferLength);
        var timeDomainData = new Uint8Array(bufferLength);

        // We want to form a sphere and to fit all the points evenly spaced in a circle we need to divide a circle
        //   into a bufferLength number of segments.
        let angleChange = (Math.PI * 2) / bufferLength;

        /**
         * The manipulation function actually performs the manipulation of the 3d scene to produce the visualisation
         *   effect.
         * On each run it will request a new frame, get the frequency and time domain data and then 
         *   calculate the new position of each of the points and the colour.
         * The X and Y positions are based on the time domain data as there is a much more even distribution of 
         *   changed values and the Z position is based on the frequency data as this tends to be biased to one side
         *   with a lot of frequencies dropping to 0.
         * The color is determined by the time domain data
         */
        function manipulate() {
            requestAnimationFrame(manipulate);

            analyser.getByteFrequencyData(frequencyData);
            analyser.getByteTimeDomainData(timeDomainData);

            // Holds the angle that we are actually at when calculating the location of points
            let activeAngle = 0;

            for (let i = 0; i < bufferLength; i++) {
            	// Get the sphere that represents this position in the buffer
                let element = pointMapping[i];

                // Calculate the x and y location. We need to work out the radius of the sphere the point
                //   is being drawn to and we know that the maximum value we can receive is 255 so we turn it
                //   into a muliitpler and then times it by the scale to form the radius
                // Then using standard trig we can work out the x and y positions using the parametric equations
                //   of a circle
                var v = (timeDomainData[i] / 255.0);
                var r = scale * v;
                let x = r * Math.cos(activeAngle);
                let y = r * Math.sin(activeAngle);

                // Assign the position of the element
                element.position.x = x;
                element.position.y = y;
                element.position.z = (frequencyData[i] / 255.0 * scale) - (scale / 2);

                // And get the color, this just uses the time domain data as we generated 255 color stops and
                //   this should produce a more varied output than the frequency data
                let color = getStop(timeDomainData[i]);
                element.material.color.r = color[0] / 255.0;
                element.material.color.g = color[1] / 255.0;
                element.material.color.b = color[2] / 255.0;

                // And increment the angle offset
                activeAngle += angleChange;
            }

        }

        // At this point the audio is loaded and everything is prepared to start the manipulation which will
        //   place all of the spheres into their initial positions and set up the colors
        manipulate();

        // Start and stop the music straight away so that we can set up the correct context allowing it to be
        //   controlled from elsewhere (the handlers below)
        sound.play();
        sound.stop();
    });
}

// These are the basic controls for starting and stopping the music. This should be pretty self explanatory.
$(document).keypress(function(e) {
    if (e.key === "s" && sound !== null) sound.stop();
    if (e.key === "r" && sound !== null) sound.play();
})